{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synapse-retail-project"
		},
		"synapse-retail-project-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'synapse-retail-project-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:synapse-retail-project.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"synapse-retail-project-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://retaildatalaketest.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/synapse-retail-project-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('synapse-retail-project-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synapse-retail-project-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('synapse-retail-project-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/01_bronze_to_silver')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkretail",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "1",
						"spark.autotune.trackingId": "bdc17a7b-f02d-4c27-bb2f-5b63508971b5"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/2b5d764b-95af-46b2-bb8a-13c0d7842524/resourceGroups/rg-retail-project/providers/Microsoft.Synapse/workspaces/synapse-retail-project/bigDataPools/sparkretail",
						"name": "sparkretail",
						"type": "Spark",
						"endpoint": "https://synapse-retail-project.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkretail",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.5",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Read Bronze Data Tests Synapse CI/CD workflow trigger"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"ms_comments": [
								{
									"threadId": "82c2bff5-33ff-45d3-8b88-e7f15e926e68",
									"text": "Read Bronze Data",
									"status": "active",
									"user": {
										"name": "Amardeep Singh",
										"idType": "aad"
									},
									"createdDateUTC": 1766672115404,
									"modifiedDateUTC": 1766672115404,
									"replies": []
								}
							],
							"ms_comment_ranges": {
								"82c2bff5-33ff-45d3-8b88-e7f15e926e68": {
									"text": "bronze_path",
									"start": {
										"line": 1,
										"column": 1
									},
									"end": {
										"line": 1,
										"column": 12
									}
								}
							}
						},
						"source": [
							"bronze_path = \"abfss://retail@retaildatalaketest.dfs.core.windows.net/bronze/retail_sales.csv\"\n",
							"\n",
							"df = spark.read \\\n",
							"    .option(\"header\", \"true\") \\\n",
							"    .csv(bronze_path)\n",
							"\n",
							"df.show(5)\n",
							"df.printSchema()\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Clean & enrich → Silver DataFrame"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql.functions import col\n",
							"\n",
							"silver_df = df \\\n",
							"    .withColumn(\"quantity\", col(\"quantity\").cast(\"int\")) \\\n",
							"    .withColumn(\"price\", col(\"price\").cast(\"double\")) \\\n",
							"    .withColumn(\"total_amount\", col(\"quantity\") * col(\"price\")) \\\n",
							"    .dropna(subset=[\"quantity\", \"price\"])  # Removes rows where quantity or price is null\n",
							"\n",
							"print(\"Silver row count after cleaning:\", silver_df.count())\n",
							"silver_df.show(5)\n",
							"silver_df.printSchema()"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Write as Delta Lake to Silver layer"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"silver_path = \"abfss://retail@retaildatalaketest.dfs.core.windows.net/silver/retail_sales\"\n",
							"\n",
							"silver_df.write \\\n",
							"    .format(\"delta\") \\\n",
							"    .mode(\"overwrite\") \\\n",
							"    .option(\"overwriteSchema\", \"true\") \\\n",
							"    .save(silver_path)\n",
							"\n",
							"print(\"✅ Silver layer successfully written as Delta Lake!\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"source": [
							"# Verify the silver Delta table\n",
							"silver_check = spark.read.format(\"delta\").load(silver_path)\n",
							"\n",
							"print(\"Verification - Silver row count:\", silver_check.count())\n",
							"silver_check.show(10)"
						],
						"outputs": [],
						"execution_count": 6
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/02_silver_to_gold')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkretail",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": true,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "3ca255d7-7b42-468f-b383-58e00e7fdb7c"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/2b5d764b-95af-46b2-bb8a-13c0d7842524/resourceGroups/rg-retail-project/providers/Microsoft.Synapse/workspaces/synapse-retail-project/bigDataPools/sparkretail",
						"name": "sparkretail",
						"type": "Spark",
						"endpoint": "https://synapse-retail-project.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkretail",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.5",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Read Silver"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"# Silver path (from previous notebook)\n",
							"silver_path = \"abfss://retail@retaildatalaketest.dfs.core.windows.net/silver/retail_sales\"\n",
							"\n",
							"# Read the clean silver Delta table\n",
							"silver_df = spark.read.format(\"delta\").load(silver_path)\n",
							"\n",
							"print(\"Silver row count:\", silver_df.count())\n",
							"silver_df.show(5)\n",
							"silver_df.printSchema()"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Business Aggregations (Gold Layer Logic)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from pyspark.sql.functions import sum, round\n",
							"\n",
							"# Aggregate by product_category\n",
							"gold_df = silver_df.groupBy(\"category\") \\\n",
							"    .agg(\n",
							"        sum(\"quantity\").alias(\"total_units\"),\n",
							"        sum(\"total_amount\").alias(\"revenue\")\n",
							"    ) \\\n",
							"    .withColumn(\"revenue\", round(col(\"revenue\"), 2))  # Nice rounded currency\n",
							"\n",
							"# Sort for readability\n",
							"gold_df = gold_df.orderBy(col(\"revenue\").desc())\n",
							"\n",
							"print(\"Gold summary row count:\", gold_df.count())\n",
							"gold_df.show(20, truncate=False)  # Show all categories"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Write Gold Layer as Delta"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"# Gold path - summarized business metrics\n",
							"gold_path = \"abfss://retail@retaildatalaketest.dfs.core.windows.net/gold/retail_sales_summary\"\n",
							"\n",
							"gold_df.write \\\n",
							"    .format(\"delta\") \\\n",
							"    .mode(\"overwrite\") \\\n",
							"    .option(\"overwriteSchema\", \"true\") \\\n",
							"    .save(gold_path)\n",
							"\n",
							"print(\"✅ Gold layer successfully written as Delta Lake!\")"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Quick Verification"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"# Read back to confirm\n",
							"gold_check = spark.read.format(\"delta\").load(gold_path)\n",
							"gold_check.show(20, truncate=False)"
						],
						"outputs": [],
						"execution_count": 17
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/retail_summary')]",
			"type": "Microsoft.Synapse/workspaces/databases",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"Ddls": [
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "retail_summary",
							"EntityType": "DATABASE",
							"Origin": {
								"Type": "SPARK"
							},
							"Properties": {
								"IsSyMSCDMDatabase": true
							},
							"Source": {
								"Provider": "ADLS",
								"Location": "abfss://retail@retaildatalaketest.dfs.core.windows.net/retail_summary",
								"Properties": {
									"FormatType": "csv",
									"LinkedServiceName": "synapse-retail-project-WorkspaceDefaultStorage"
								}
							},
							"PublishStatus": "PUBLISHED",
							"ObjectVersion": 1,
							"ObjectId": "55c83c24-5016-4170-94b0-e49b476696e9"
						},
						"Source": {
							"Type": "SPARK"
						}
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sparkretail')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 5
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.5",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "northeurope"
		}
	]
}